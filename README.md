# Mini Batch Gradient Descent Algorithm
 This Github repository contains a Jupyter Notebook that implements the mini-batch gradient descent algorithm, a popular optimization algorithm used in machine learning for training various models. The notebook is written in Python and uses popular scientific computing libraries, including NumPy and Matplotlib.

The notebook provides a step-by-step implementation of the mini-batch gradient descent algorithm, which is a variant of batch gradient descent that updates the model's parameters using small batches of training data instead of the entire dataset. The implementation includes a detailed explanation of the algorithm, including how to calculate the gradient and how to update the model parameters using mini-batches.

The notebook also includes an example of applying mini-batch gradient descent to linear regression. You can follow along with the examples and see how mini-batch gradient descent can be used to optimize the models' parameters and improve their performance.

Kindly upload the CSV file to the path in which the Notebook will be run for successful execution of the code.
